tosca_definitions_version: cloudify_dsl_1_3


description: >
  Example blueprint for AWS EMR functionality.
  
  Prerequisites:
  1. S3 bucket for cluster logging (emr_cluster_s3_log_path)
  2. AWS API credentials (aws_access_key_id & aws_secret_access_key)
  
  This will spin up a new EMR cluster with a MASTER node and 1 or more
  CORE nodes. It will have a couple of bootstrap actions, 1 to
  install Node.js and 1 to copy a custom UDF (or whatever you specify
  in emr_bsa_hive_udf_path) to the cluster. Then it will
  start a new cluster step (process) and run the example
  WordCount step from Amazon.
  
  To scale the number of CORE nodes in the cluster, run the
  scale_emr_cluster_instance_group workflow. Note, scaling
  can only work if there was an instance group created with the
  cluster at deployment time. AWS does not allow for creating
  cluster instance groups at run-time. 


imports:
- http://www.getcloudify.org/spec/cloudify/3.4.1/types.yaml
- https://raw.githubusercontent.com/01000101/cloudify-aws-plugin/emr/plugin.yaml


inputs:
  aws_access_key_id:
    type: string
  
  aws_secret_access_key:
    type: string
    
  aws_region_name:
    type: string
  
  emr_cluster_name:
    description: >
      Name of the EMR cluster to create
    type: string
  
  emr_cluster_ec2_keyname:
    description: >
      Name of AWS EC2 keypair to use for the EMR cluster
    type: string
    
  emr_cluster_applications:
    description: >
      List of EMR cluster applications (names) to be install
    default: []
    
  emr_cluster_s3_log_path:
    description: >
      S3 path to a folder to hold EMR cluster logs
    type: string
    
  emr_cluster_core_instances_type:
    description: >
      Type (size / flavor) of CORE cluster instances
    type: string
    default: m3.xlarge
    
  emr_cluster_core_instances_count:
    description: >
      Number of CORE cluster instances to spawn on create
    type: integer
    default: 1
    
  emr_bsa_hive_udf_path:
    description: >
      S3 bucket path of a custom UDF to place on the cluster
    type: string
    
  emr_bsa_nodejs_path:
    description: >
      S3 bucket folder path to a script that will install Node.js
    type: string
    
  emr_wordcount_input_path:
    description: >
      S3 bucket path to put the WordCount step input.
    type: string
    
  emr_wordcount_output_path:
    description: >
      S3 bucket path to put the WordCount step results. The bucket
      should exist, but the path directory should not. It will be
      created by EMR and will fail if it exists.
    type: string


dsl_definitions:
  aws_config: &aws_config
    aws_access_key_id: { get_input: aws_access_key_id }
    aws_secret_access_key: { get_input: aws_secret_access_key }
    ec2_region_name: { get_input: aws_region_name }


node_templates:
  emr_cluster:
    type: cloudify.aws.nodes.emr.Cluster
    properties:
      name: { get_input: emr_cluster_name }
      log_uri: { get_input: emr_cluster_s3_log_path }
      ec2_keyname: { get_input: emr_cluster_ec2_keyname }
      applications: { get_input: emr_cluster_applications }
      aws_config: *aws_config
    relationships:
    - target: bootstrap_copy_hive_udf
      type: cloudify.aws.relationships.emr.cluster_connected_to_bootstrap_action
    - target: bootstrap_install_nodejs
      type: cloudify.aws.relationships.emr.cluster_connected_to_bootstrap_action
    - target: instance_group_master
      type: cloudify.aws.relationships.emr.cluster_connected_to_instance_group
    - target: instance_group_core
      type: cloudify.aws.relationships.emr.cluster_connected_to_instance_group
    
  ###
  # Cluster Instance Groups
  ###
  instance_group_master:
    type: cloudify.aws.nodes.emr.InstanceGroup
    properties:
      name: Master node
      role: MASTER
      type: m1.medium
      
  instance_group_core:
    type: cloudify.aws.nodes.emr.InstanceGroup
    properties:
      name: Core node
      role: CORE
      type: { get_input: emr_cluster_core_instances_type }
      num_instances: { get_input: emr_cluster_core_instances_count }

  ###
  # Cluster Bootstrap Actions
  ###
  # Use local scripts to fetch external resources in S3
  bootstrap_copy_hive_udf:
    type: cloudify.aws.nodes.emr.BootstrapAction
    properties:
      name: "Copy Custom Hive UDF"
      path: "file:///usr/bin/aws"
      bootstrap_action_args:
      - s3
      - cp
      - { get_input: emr_bsa_hive_udf_path }
      - "/home/hadoop/"

  # Run a bootstrap action directly from S3
  bootstrap_install_nodejs:
    type: cloudify.aws.nodes.emr.BootstrapAction
    properties:
      name: "Install Node.js"
      path: { get_input: emr_bsa_nodejs_path }

  ###
  # Cluster Steps
  ###
  # This is the traditional WordCount EMR example step from Amazon
  step_wordcount:
    type: cloudify.aws.nodes.emr.StreamingStep
    properties:
      name: Sample Word Count
      input: { get_input: emr_wordcount_input_path }
      mapper: wordSplitter.py
      reducer: aggregate
      output: { get_input: emr_wordcount_output_path }
      step_args:
      - hadoop-streaming
      - "-files"
      - "s3://elasticmapreduce/samples/wordcount/wordSplitter.py"
      aws_config: *aws_config
    relationships:
    - target: emr_cluster
      type: cloudify.aws.relationships.emr.step_contained_in_cluster
